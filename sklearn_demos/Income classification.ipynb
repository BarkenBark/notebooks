{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data and load it in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = (\"https://archive.ics.uci.edu/ml/machine-learning-databases\"\n",
    "       \"/adult/adult.data\")\n",
    "local_filename = os.path.basename(url)\n",
    "if not os.path.exists(local_filename):\n",
    "    print(\"Downloading Adult Census datasets from UCI\")\n",
    "    urlretrieve(url, local_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = (\"age, workclass, fnlwgt, education, education-num, \"\n",
    "         \"marital-status, occupation, relationship, race, sex, \"\n",
    "         \"capital-gain, capital-loss, hours-per-week, \"\n",
    "         \"native-country, income\").split(', ')    \n",
    "data = pd.read_csv(local_filename, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.hist(column='education-num', bins=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.hist(column='age', bins=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.hist('hours-per-week', bins=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.plot(x='age', y='hours-per-week', kind='scatter',\n",
    "          alpha=0.02, s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.groupby('income')['income'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(data['income'] == ' >50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_names = data['income'].unique()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_income = data[data['income'] == ' <=50K']\n",
    "high_income = data[data['income'] == ' >50K']\n",
    "\n",
    "plt.scatter(low_income['age'], low_income['hours-per-week'],\n",
    "            alpha=0.03, s=50, c='b', label='<=50K');\n",
    "plt.scatter(high_income['age'], high_income['hours-per-week'],\n",
    "            alpha=0.03, s=50, c='g', label='>50K');\n",
    "plt.legend()\n",
    "plt.xlabel('age'); plt.ylabel('hours-per-week');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_features = [c for c in data if data[c].dtype.kind in ('i', 'f')]\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_data = data[numeric_features]\n",
    "numeric_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_data = data.drop(numeric_features, 1)\n",
    "categorical_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_data_encoded = categorical_data.apply(lambda x: pd.factorize(x)[0])\n",
    "categorical_data_encoded.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_encoded = pd.concat([numeric_data, categorical_data_encoded], axis=1)\n",
    "data_encoded.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = data_encoded.drop('income', axis=1)\n",
    "X = features.values.astype(np.float32)\n",
    "y = (data['income'].values == ' >50K').astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"ROC AUC Decision Tree: {:.4f} +/-{:.4f}\".format(\n",
    "    np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, ylim=(0, 1.1), cv=5,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5),\n",
    "                        scoring=None):\n",
    "    plt.title(\"Learning curves for %s\" % type(estimator).__name__)\n",
    "    plt.ylim(*ylim); plt.grid()\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n",
    "        scoring=scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, validation_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    print(\"Best validation score: {:.4f}\".format(validation_scores_mean[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=None)\n",
    "plot_learning_curve(clf, X_train, y_train, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=15)\n",
    "plot_learning_curve(clf, X_train, y_train, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8)\n",
    "plot_learning_curve(clf, X_train, y_train, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=4)\n",
    "plot_learning_curve(clf, X_train, y_train, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator, X, y, param_name, param_range,\n",
    "                          ylim=(0, 1.1), cv=5, n_jobs=-1, scoring=None):\n",
    "    estimator_name = type(estimator).__name__\n",
    "    plt.title(\"Validation curves for %s on %s\"\n",
    "              % (param_name, estimator_name))\n",
    "    plt.ylim(*ylim); plt.grid()\n",
    "    plt.xlim(min(param_range), max(param_range))\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name, param_range,\n",
    "        cv=cv, n_jobs=n_jobs, scoring=scoring)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    plt.semilogx(param_range, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    plt.semilogx(param_range, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    print(\"Best test score: {:.4f}\".format(test_scores_mean[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8)\n",
    "param_name = 'max_depth'\n",
    "param_range = [1, 2, 4, 8, 16, 32]\n",
    "\n",
    "plot_validation_curve(clf, X_train, y_train,\n",
    "                      param_name, param_range, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=30, max_features=10,\n",
    "                             max_depth=10)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc',\n",
    "                         n_jobs=-1)\n",
    "print(\"ROC Random Forest: {:.4f} +/-{:.4f}\".format(\n",
    "    np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_leaf_nodes=5, learning_rate=0.1,\n",
    "                                 n_estimators=100)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc',\n",
    "                         n_jobs=-1)\n",
    "print(\"ROC AUC Gradient Boosted Trees: {:.4f} +/-{:.4f}\".format(\n",
    "    np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC AUC: %0.4f\" % roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision_gb, recall_gb, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(precision_gb, recall_gb)\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.title('Precision / Recall curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ordering = np.argsort(clf.feature_importances_)[::-1]\n",
    "\n",
    "importances = clf.feature_importances_[ordering]\n",
    "feature_names = features.columns[ordering]\n",
    "\n",
    "x = np.arange(len(feature_names))\n",
    "plt.bar(x, importances)\n",
    "plt.xticks(x + 0.5, feature_names, rotation=90, fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the boosted trees to extract features for a Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of a trick found in:\n",
    "\n",
    "Practical Lessons from Predicting Clicks on Ads at Facebook\n",
    "Junfeng Pan, He Xinran, Ou Jin, Tianbing XU, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, Joaquin Quiñonero Candela\n",
    "International Workshop on Data Mining for Online Advertising (ADKDD)\n",
    "\n",
    "https://www.facebook.com/publications/329190253909587/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "class TreeTransform(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"One-hot encode samples with an ensemble of trees\n",
    "    \n",
    "    This transformer first fits an ensemble of trees (e.g. gradient\n",
    "    boosted trees or a random forest) on the training set.\n",
    "\n",
    "    Then each leaf of each tree in the ensembles is assigned a fixed\n",
    "    arbitrary feature index in a new feature space. If you have 100\n",
    "    trees in the ensemble and 2**3 leafs per tree, the new feature\n",
    "    space has 100 * 2**3 == 800 dimensions.\n",
    "    \n",
    "    Each sample of the training set go through the decisions of each tree\n",
    "    of the ensemble and ends up in one leaf per tree. The sample if encoded\n",
    "    by setting features with those leafs to 1 and letting the other feature\n",
    "    values to 0.\n",
    "    \n",
    "    The resulting transformer learn a supervised, sparse, high-dimensional\n",
    "    categorical embedding of the data.\n",
    "    \n",
    "    This transformer is typically meant to be pipelined with a linear model\n",
    "    such as logistic regression, linear support vector machines or\n",
    "    elastic net regression.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.fit_transform(X, y)\n",
    "        return self\n",
    "        \n",
    "    def fit_transform(self, X, y):\n",
    "        self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.fit(X, y)\n",
    "        self.binarizers_ = []\n",
    "        sparse_applications = []\n",
    "        estimators = np.asarray(self.estimator_.estimators_).ravel()\n",
    "        for t in estimators:\n",
    "            lb = LabelBinarizer(sparse_output=True)\n",
    "            sparse_applications.append(lb.fit_transform(t.tree_.apply(X)))\n",
    "            self.binarizers_.append(lb)\n",
    "        return hstack(sparse_applications)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        sparse_applications = []\n",
    "        estimators = np.asarray(self.estimator_.estimators_).ravel()\n",
    "        for t, lb in zip(estimators, self.binarizers_):\n",
    "            sparse_applications.append(lb.transform(t.tree_.apply(X)))\n",
    "        return hstack(sparse_applications)\n",
    "\n",
    "\n",
    "boosted_trees = GradientBoostingClassifier(\n",
    "    max_leaf_nodes=5, learning_rate=0.1,\n",
    "    n_estimators=100, random_state=0,\n",
    ") \n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TreeTransform(boosted_trees),\n",
    "    LogisticRegression(C=1)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC AUC: %0.4f\" % roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision_gb_lr, recall_gb_lr, _ = precision_recall_curve(\n",
    "    y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(precision_gb, recall_gb, label='GBT')\n",
    "plt.plot(precision_gb_lr, recall_gb_lr, label='GBT + LR')\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.title('Precision / Recall curve')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
