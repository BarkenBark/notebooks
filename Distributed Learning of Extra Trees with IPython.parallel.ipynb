{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "import bz2\n",
      "import numpy as np\n",
      "from os.path import expanduser, join, exists\n",
      "\n",
      "DATA_FOLDER = expanduser('~/data/mnist8m')\n",
      "MNIST8M_SRC_URL = ('http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/'\n",
      "                   'datasets/multiclass/mnist8m.bz2')\n",
      "MNIST8M_SRC_FILENAME = MNIST8M_SRC_URL.rsplit('/', 1)[1]\n",
      "MNIST8M_SRC_FILEPATH = join(DATA_FOLDER, MNIST8M_SRC_FILENAME)\n",
      "MNIST8M_MMAP_DATA_FILENAME = \"mnist8m_data.mmap\"\n",
      "MNIST8M_MMAP_DATA_FILEPATH = join(DATA_FOLDER, MNIST8M_MMAP_DATA_FILENAME)\n",
      "\n",
      "MNIST8M_MMAP_LABELS_FILENAME = \"mnist8m_labels.mmap\"\n",
      "MNIST8M_MMAP_LABELS_FILEPATH = join(DATA_FOLDER, MNIST8M_MMAP_LABELS_FILENAME)\n",
      "\n",
      "CHUNK_FILENAME_PREFIX = \"mnist8m-chunk-\"\n",
      "\n",
      "CHUNK_SIZE = 100000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download the `mnist8m.bz2` source file into the data folder if not previously downloaded:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not exists(DATA_FOLDER):\n",
      "    os.makedirs(DATA_FOLDER)\n",
      "\n",
      "if not exists(MNIST8M_SRC_FILEPATH):\n",
      "    cmd = \"(cd '%s' && wget -c '%s')\" % (DATA_FOLDER, MNIST8M_SRC_URL)\n",
      "    print(cmd)\n",
      "    os.system(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Decompress and chunk the source svmlight formatted data file to make it easier to process it in parallel:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunk_filenames = [fn for fn in os.listdir(DATA_FOLDER)\n",
      "                      if fn.startswith(CHUNK_FILENAME_PREFIX)]\n",
      "chunk_filenames.sort()\n",
      "\n",
      "\n",
      "if not chunk_filenames:\n",
      "    chunk_filenames = []\n",
      "    with bz2.BZ2File(MNIST8M_SRC_FILEPATH) as source:\n",
      "        target, line_no, chunk_idx = None, 0, 0\n",
      "        for line in source:\n",
      "            line_no += 1\n",
      "            if target is None:\n",
      "                chunk_filename = \"%s%03d.svmlight\" % (\n",
      "                    CHUNK_FILENAME_PREFIX, chunk_idx)\n",
      "                chunk_filename = join(DATA_FOLDER, chunk_filename)\n",
      "                target = open(chunk_filename, 'wb')\n",
      "                chunk_idx += 1\n",
      "                chunk_filenames.append(chunk_filename)\n",
      "                \n",
      "            target.write(line)\n",
      "                \n",
      "            if line_no >= CHUNK_SIZE:\n",
      "                target.close()\n",
      "                target, line_no = None, 0\n",
      "        if target is not None:\n",
      "            target.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Memory mapping utility to load or create the mmap data files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_mmap_data(data_filepath, labels_filepath, mode=None, order='C'):\n",
      "    import numpy as np\n",
      "    from os.path import exists\n",
      "\n",
      "    n_samples, n_features = 8100000, 28 ** 2\n",
      "    shape = (n_samples, n_features)\n",
      "    \n",
      "    # Reopen the existing data map if it already exists, otherwise create it\n",
      "    if mode is None:\n",
      "        mode_data = 'r+' if exists(data_filepath) else 'w+'\n",
      "    else:\n",
      "        mode_data = mode\n",
      "    data = np.memmap(data_filepath, shape=shape,\n",
      "                     dtype=np.float32, mode=mode_data, order=order)\n",
      "    \n",
      "    if mode is None:\n",
      "        mode_labels = 'r+' if exists(labels_filepath) else 'w+'\n",
      "    else:\n",
      "        mode_labels = mode\n",
      "    labels = np.memmap(labels_filepath, shape=n_samples,\n",
      "                       dtype=np.int32, mode=mode_labels)\n",
      "    return data, labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Trigger the creation of the mmap files with zero data if missing.\n",
      "data, labels = get_mmap_data(MNIST8M_MMAP_DATA_FILEPATH,\n",
      "                             MNIST8M_MMAP_LABELS_FILEPATH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initialization of the IPython.parallel cluster client"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client = Client()\n",
      "lb_view = client.load_balanced_view()\n",
      "len(lb_view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "31"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ship the definition of the mmap loading helper function to the\n",
      "# worker processes\n",
      "client[:][get_mmap_data.__name__] = get_mmap_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initialization of the contiguous mmap data files from the svmlight formatted chunks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use IPython.parallel to parse the svmlight formatted chunks and store the resulting data into a single precision float, C contiguous array suitable for training ensembles of trees."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_chunk(task_info):\n",
      "    from sklearn.datasets import load_svmlight_file\n",
      "    from os.path import join\n",
      "    chunk_index, chunk_filename, chunk_size = task_info[:3]\n",
      "    data_filepath, labels_filepath = task_info[3:]\n",
      "    data, labels = get_mmap_data(data_filepath,\n",
      "                                 labels_filepath,\n",
      "                                 mode='r+')\n",
      "    X, y = load_svmlight_file(chunk_filename, n_features=28 ** 2)\n",
      "    region = slice(chunk_index * chunk_size,\n",
      "                   (chunk_index + 1) * chunk_size)\n",
      "    data[region, :] = X.toarray() / 255.\n",
      "    labels[region] = y\n",
      "\n",
      "    \n",
      "task_infos = [(chunk_index,\n",
      "               join(DATA_FOLDER, chunk_filename),\n",
      "               CHUNK_SIZE,\n",
      "               MNIST8M_MMAP_DATA_FILEPATH,\n",
      "               MNIST8M_MMAP_LABELS_FILEPATH)\n",
      "              for chunk_index, chunk_filename in enumerate(chunk_filenames)]\n",
      "\n",
      "result = lb_view.map(parse_chunk, task_infos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result.get()\n",
      "%time data.max(), labels.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time data.max(), labels.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train, labels_train = data[:-100000], labels[:-100000]\n",
      "data_test, labels_test = data[-100000:], labels[-100000:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_trees(train_trees_params):\n",
      "    from sklearn.ensemble import ExtraTreesClassifier\n",
      "    \n",
      "    n_estimators, random_state, n_samples = train_trees_params[:3]\n",
      "    data_file, labels_file  = train_trees_params[3:]\n",
      "    data, labels = get_mmap_data(data_file, labels_file, mode='r')\n",
      "    data_train, labels_train = data[:n_samples], labels[:n_samples]\n",
      "    ensemble = ExtraTreesClassifier(n_estimators=n_estimators,\n",
      "                                    random_state=random_state)\n",
      "    ensemble.fit(data_train, labels_train)\n",
      "    return ensemble\n",
      "\n",
      "train_result = lb_view.map(\n",
      "    train_trees,\n",
      "    [(1, i, int(8e6),\n",
      "      MNIST8M_MMAP_DATA_FILEPATH,\n",
      "      MNIST8M_MMAP_LABELS_FILEPATH) for i in range(30)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_result.ready(), train_result.progress, len(train_result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Total training time in second (not optimum due to the lack of CPU affinity):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_result.elapsed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_ensembles = train_result.get()\n",
      "first_clf = all_ensembles[0]\n",
      "first_clf.n_classes_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "individual_scores = [clf.score(data_test, labels_test) for clf in all_ensembles]\n",
      "np.mean(individual_scores), np.std(individual_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import copy\n",
      "\n",
      "final_clf = copy(first_clf)\n",
      "for clf in all_ensembles[1:]:\n",
      "    final_clf.estimators_ += clf.estimators_\n",
      "final_clf.n_estimators = len(final_clf.estimators_)\n",
      "    \n",
      "%time final_clf_score = final_clf.score(data_test, labels_test)\n",
      "print(final_clf_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm -f $DATA_FOLDER/model.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.externals import joblib\n",
      "\n",
      "model_files = joblib.dump(final_clf, DATA_FOLDER + '/model.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "model_size = sum([os.stat(f).st_size for f in model_files])\n",
      "print(\"Total model size: {}MB\".format(int(model_size / 1e6)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Single process training and evaluation (sanity check)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "ensemble = ExtraTreesClassifier(n_estimators=1, random_state=0)\n",
      "%time ensemble.fit(data_train, labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time ensemble.score(data_test, labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.externals import joblib\n",
      "\n",
      "joblib.dump(ensemble, DATA_FOLDER + '/model.pkl')\n",
      "!ls -lh $DATA_FOLDER/model.*.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setting Process-CPU affinity"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def collect_host_infos(direct_view):\n",
      "    # Collect the information\n",
      "    def get_pid_host_cpucount():\n",
      "        import os\n",
      "        import socket\n",
      "        import multiprocessing as mp\n",
      "        return socket.gethostname(), mp.cpu_count(), os.getpid()\n",
      "    \n",
      "    engine_info = direct_view.apply(get_pid_host_cpucount).get_dict()\n",
      "\n",
      "    # Group info by hosts in nested dicts\n",
      "    info_by_host = defaultdict(dict)\n",
      "    for engine_id, info in engine_info.items():\n",
      "        host_info = info_by_host[info[0]]\n",
      "        host_info['cpu_count'] = info[1]\n",
      "        host_info.setdefault('engine_pids', {})[engine_id] = info[2]\n",
      "    \n",
      "    return info_by_host"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def assign_engines(direct_view, verbose=False):\n",
      "    \"\"\"Assign each engine to a specific CPU on it hosts.\"\"\"\n",
      "\n",
      "    def taskset(engine_pids, verbose=False):\n",
      "        import os\n",
      "        import socket\n",
      "        import multiprocessing as mp\n",
      "        cpu_count = mp.cpu_count()\n",
      "        for i, pid in enumerate(engine_pids):\n",
      "            cpu_id = i % cpu_count\n",
      "            cmd = \"taskset -p -c {} {}\".format(cpu_id, pid)\n",
      "            if os.system(cmd) != 0:\n",
      "                err_msg = \"Command '{}' failed on host: {}\"\n",
      "                raise RuntimeError(err_msg.format(\n",
      "                    cmd, socket.gethostname()))\n",
      "    \n",
      "    tasks = []\n",
      "    host_infos = collect_host_infos(direct_view)\n",
      "    for host_info in host_infos.values():\n",
      "        client = direct_view.client\n",
      "        pid_map = host_info['engine_pids']\n",
      "        engine_pids = list(sorted(pid_map.values()))    \n",
      "        ctl_engine_view = client[pid_map.keys()[0]]\n",
      "        tasks.append(ctl_engine_view.apply(taskset, engine_pids, verbose))\n",
      "        \n",
      "    # Wait for completion\n",
      "    [t.r for t in tasks]\n",
      "\n",
      "\n",
      "assign_engines(client[:], verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    }
   ],
   "metadata": {}
  }
 ]
}