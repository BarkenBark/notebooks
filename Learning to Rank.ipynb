{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from os.path import expanduser, join\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.metrics import r2_score\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.ensemble import ExtraTreesRegressor\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "from pyrallel.ensemble import EnsembleGrower\n",
      "from pyrallel.ensemble import sub_ensemble"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "lb_view = Client().load_balanced_view()\n",
      "len(lb_view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading the dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a NumPy array version of Fold1 of the [MSLR-WEB10K](http://research.microsoft.com/en-us/projects/mslr/) dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "data = np.load(expanduser('~/data/MSLR-WEB10K/mslr-web10k_fold1.npz'))\n",
      "X_train, y_train, qid_train = data['X_train'], data['y_train'], data['qid_train']\n",
      "X_vali, y_vali, qid_vali = data['X_vali'], data['y_vali'], data['qid_vali']\n",
      "X_test, y_test, qid_test = data['X_test'], data['y_test'], data['qid_test']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Total size in bytes, total number of search results and number of queries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(X_train.nbytes + X_vali.nbytes + X_test.nbytes) / 1e6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(X_train) + len(X_vali) + len(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(np.unique(qid_train)) + len(np.unique(qid_vali)) + len(np.unique(qid_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Concatenate the training and validation sets as a big development set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_dev = np.vstack([X_train, X_vali])\n",
      "y_dev = np.concatenate([y_train, y_vali])\n",
      "qid_train = np.concatenate([qid_train, qid_vali])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_dev.shape, X_dev.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_qid_train = np.unique(qid_train)\n",
      "len(unique_qid_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract a subset of 500 queries to speed up the learning when prototyping"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng = np.random.RandomState(0)\n",
      "qid_mask = rng.permutation(len(unique_qid_train))[:500]\n",
      "subset_mask = np.in1d(qid_train, unique_qid_train[qid_mask])\n",
      "X_train_small = X_train[subset_mask]\n",
      "y_train_small = y_train[subset_mask]\n",
      "qid_train_small = qid_train[subset_mask]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_small.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sanity check:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(np.unique(qid_train_small))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Quantifying ranking success with NDCG"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dcg(relevances, rank=10):\n",
      "    \"\"\"Discounted cumulative gain at rank (DCG)\"\"\"\n",
      "    relevances = np.asarray(relevances)[:rank]\n",
      "    n_relevances = len(relevances)\n",
      "    if n_relevances == 0:\n",
      "        return 0.\n",
      "\n",
      "    discounts = np.log2(np.arange(n_relevances) + 2)\n",
      "    return np.sum(relevances / discounts)\n",
      " \n",
      " \n",
      "def ndcg(relevances, rank=10):\n",
      "    \"\"\"Normalized discounted cumulative gain (NDGC)\"\"\"\n",
      "    best_dcg = dcg(sorted(relevances, reverse=True), rank)\n",
      "    if best_dcg == 0:\n",
      "        return 0.\n",
      "\n",
      "    return dcg(relevances, rank) / best_dcg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndcg([2, 4, 0, 1, 1, 0, 0], rank=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndcg([0, 0, 0, 1, 1, 2, 4], rank=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndcg([0, 0, 0, 1, 1, 2, 4], rank=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndcg([4, 2, 1, 1, 0, 0, 0], rank=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_ndcg(y_true, y_pred, query_ids, rank=10):\n",
      "    y_true = np.asarray(y_true)\n",
      "    y_pred = np.asarray(y_pred)\n",
      "    query_ids = np.asarray(query_ids)\n",
      "    # assume query_ids are sorted\n",
      "    ndcg_scores = []\n",
      "    previous_qid = query_ids[0]\n",
      "    previous_loc = 0\n",
      "    for loc, qid in enumerate(query_ids):\n",
      "        if previous_qid != qid:\n",
      "            chunk = slice(previous_loc, loc)\n",
      "            ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
      "            ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
      "            previous_loc = loc\n",
      "        previous_qid = qid\n",
      "\n",
      "    chunk = slice(previous_loc, loc + 1)\n",
      "    ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
      "    ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
      "    return np.mean(ndcg_scores)\n",
      "\n",
      "\n",
      "mean_ndcg([4, 3, 1, 4, 3], [4, 0, 1, 4, 2], [0, 0, 0, 2, 2], rank=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Growing Randomized Trees to predict relevance scores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grower = EnsembleGrower(lb_view, ExtraTreesRegressor(n_estimators=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grower.launch(X_train, y_train, n_estimators=500, folder=\"mlsr-web10k\", name='etr')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grower"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#grower.wait()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time etr = grower.aggregate_model()\n",
      "print(\"number of trees: {}\".format(len(etr.estimators_)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time y_vali_etr = etr.predict(X_vali)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"NDCG_3 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_vali, y_vali_etr, qid_vali, rank=3)))\n",
      "print(\"NDCG_10 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_vali, y_vali_etr, qid_vali, rank=10)))\n",
      "print(\"R2 score: {:.3f}\".format(r2_score(y_vali, y_vali_etr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Impact of the number of trees in the ensemble"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "max_n_trees = len(etr.estimators_)\n",
      "n_trees = np.logspace(0, np.log10(max_n_trees), 5).astype(int)\n",
      "scores = []\n",
      "\n",
      "for j, n in enumerate(n_trees):\n",
      "    y_predicted = sub_ensemble(etr, n).predict(X_vali)\n",
      "    scores.append(mean_ndcg(y_vali, y_predicted, qid_vali, rank=10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(n_trees, scores)\n",
      "plt.xlabel(\"Number of trees\")\n",
      "plt.ylabel(\"Average NDC@10\")\n",
      "_ = plt.title(\"Impact of the number of trees\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Evaluation of the overfitting of the ensemble"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time y_train_small_etr = etr.predict(X_train_small)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"NDCG_3 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_train_small, y_train_small_etr, qid_train_small, rank=3)))\n",
      "print(\"NDCG_10 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_train_small, y_train_small_etr, qid_train_small, rank=10)))\n",
      "print(\"R2 score: {:.3f}\".format(r2_score(y_train_small, y_train_small_etr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comparing with a baseline linear regression model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time lr = LinearRegression().fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time y_vali_lr = lr.predict(X_vali)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"NDCG_3 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_vali, y_vali_lr, qid_vali, rank=3)))\n",
      "print(\"NDCG_10 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_vali, y_vali_lr, qid_vali, rank=10)))\n",
      "print(\"R2 score: {:.3f}\".format(r2_score(y_vali, y_vali_lr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Evaluate overfitting by comparing with training set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_small_lr = lr.predict(X_train_small)\n",
      "\n",
      "print(\"NDCG_3 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_train_small, y_train_small_lr, qid_train_small, rank=3)))\n",
      "print(\"NDCG_10 score: {:.3f}\".format(\n",
      "    mean_ndcg(y_train_small, y_train_small_lr, qid_train_small, rank=10)))\n",
      "print(\"R2 score: {:.3f}\".format(r2_score(y_train_small, y_train_small_lr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Interestingly enough, a overfitting of the training set from a regression standpoint (higher r2 score) does not seem to cause overfitting from a ranking standpoint. This would have to be checked with cross-validation though."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introspecting the distribution of relevance scores predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subset = np.random.permutation(y_vali.shape[0])[:10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.title('Extra Trees predictions')\n",
      "plt.scatter(y_vali[subset], y_vali_etr[subset], alpha=0.01, s=100)\n",
      "plt.xlabel('True relevance')\n",
      "plt.ylabel('Predicted relevance')\n",
      "plt.ylim(-2, 5)\n",
      "plt.xlim(-2, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.title('Linear Regression predictions')\n",
      "plt.scatter(y_vali[subset], y_vali_lr[subset], alpha=0.01, s=100)\n",
      "plt.xlabel('True relevance')\n",
      "plt.ylabel('Predicted relevance')\n",
      "plt.ylim(-2, 5)\n",
      "plt.xlim(-2, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(y_vali, bins=5, alpha=.3, color='b', label='True relevance')\n",
      "plt.hist(y_vali_etr, bins=5, alpha=.3, color='g', label='ET predicted relevance')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For each query, count the number of results with rank 0, 1, 2, 3 or 4."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_qids_vali = np.unique(qid_vali)\n",
      "for qid in unique_qids_vali[:10]:\n",
      "    qids = y_vali[qid_vali == qid].astype(np.int)\n",
      "    print(np.bincount(qids, minlength=5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}