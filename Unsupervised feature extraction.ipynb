{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.preprocessing import scale\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.neural_network import MultilayerPerceptronClassifier\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "digits = load_digits()\n",
      "X_dev, X_eval, y_dev, y_eval = train_test_split(digits.data, digits.target, test_size=0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "\n",
      "def make_scaling_lr(**params):\n",
      "    return Pipeline([\n",
      "        ('scaler', StandardScaler()),\n",
      "        ('classifier', LogisticRegression(**params))          \n",
      "    ])\n",
      "\n",
      "\n",
      "def make_scaling_mlp(**params):\n",
      "    return Pipeline([\n",
      "        ('scaler', StandardScaler()),\n",
      "        ('classifier', MultilayerPerceptronClassifier(**params))          \n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = make_scaling_lr(C=0.1).fit(X_dev, y_dev)\n",
      "lr.score(X_eval, y_eval)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = make_scaling_mlp(n_hidden=100, alpha=1).fit(X_dev, y_dev)\n",
      "nn.score(X_eval, y_eval)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "0.97777777777777775"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(nn, X_dev, y_dev, cv=5, n_jobs=-1)\n",
      "print(np.mean(scores), np.std(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.97842382888114598, 0.0086432579976436687)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shuffle_columns(X, copy=True, seed=None):\n",
      "    rng = np.random.RandomState(seed)\n",
      "    if copy:\n",
      "        X = X.copy()\n",
      "    for i in range(X.shape[1]):\n",
      "        rng.shuffle(X[:, i])\n",
      "    return X\n",
      "\n",
      "\n",
      "def make_membership_pbm(X, seed=0):\n",
      "    rng = np.random.RandomState(seed)\n",
      "    n_samples, n_features = X.shape\n",
      "    shuffle_idx = rng.permutation(2 * n_samples)\n",
      "    \n",
      "    X = np.vstack([X, shuffle_columns(X, seed=seed)])\n",
      "    y = np.concatenate([np.ones(n_samples), -np.ones(n_samples)])\n",
      "    return X[shuffle_idx], y[shuffle_idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_mem_dev, y_mem_dev = make_membership_pbm(X_dev)\n",
      "\n",
      "X_mem_dev.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "(2874, 64)"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "nn = make_scaling_mlp(n_hidden=100, alpha=1)\n",
      "scores = cross_val_score(nn, X_mem_dev, y_mem_dev, cv=5, n_jobs=-1)\n",
      "print(np.mean(scores), np.std(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.98155733979700055, 0.0053495788516786241)\n",
        "CPU times: user 24 ms, sys: 40 ms, total: 64 ms\n",
        "Wall time: 6.07 s\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time _ = nn.fit(X_mem_dev, y_mem_dev)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 8.68 s, sys: 120 ms, total: 8.8 s\n",
        "Wall time: 6.77 s\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.utils.extmath import safe_sparse_dot\n",
      "\n",
      "def hidden_activate(nn, X):\n",
      "    a = safe_sparse_dot(X, nn.coef_hidden_) + nn.intercept_hidden_\n",
      "    return nn.activation_func(a)\n",
      "\n",
      "X_dev_1 = hidden_activate(nn.named_steps['classifier'], X_dev)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_mem_dev_2, y_mem_dev_2 = make_membership_pbm(X_dev_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "nn = make_scaling_mlp(n_hidden=100, alpha=1)\n",
      "scores = cross_val_score(nn, X_mem_dev_2, y_mem_dev_2, cv=5, n_jobs=-1)\n",
      "print(np.mean(scores), np.std(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.99791122557188294, 0.0025582173831189383)\n",
        "CPU times: user 32 ms, sys: 52 ms, total: 84 ms\n",
        "Wall time: 7.27 s\n"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X_dev_2 = hidden_activate(nn.fit(X_mem_dev_2, y_mem_dev_2).named_steps['classifier'], X_dev_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 10.5 s, sys: 100 ms, total: 10.6 s\n",
        "Wall time: 7.76 s\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Evaluate the benefit of adding the new features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_lr(C=1), X_dev, y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "0.96172812620983339"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_lr(C=1), np.hstack([X_dev, X_dev_1]), y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "0.96519308943089432"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(LogisticRegression(C=1), np.hstack([X_dev, X_dev_1, X_dev_2]), y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "0.96379936120789778"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_mlp(n_hidden=100, alpha=1.), np.hstack([X_dev, X_dev_1, X_dev_2]), y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "0.97215205187766163"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A significant fraction of the signal is preserve by the successive embeddings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_lr(C=1), X_dev_1, y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "0.95128000387146727"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_lr(C=1), X_dev_2, y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "0.8990853658536585"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_lr(C=1), np.hstack([X_dev_1, X_dev_2]), y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "0.95892373209446391"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compare with random non-linear embedding features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rnd = np.random.normal(scale=1., size=(X_dev.shape[1], 200))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.utils.extmath import logistic_sigmoid\n",
      "\n",
      "X_dev_proj = logistic_sigmoid(np.dot(scale(X_dev), rnd))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(make_scaling_lr(C=1), np.hstack([X_dev, X_dev_proj]), y_dev, cv=5, n_jobs=-1).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "0.9568500774293458"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}